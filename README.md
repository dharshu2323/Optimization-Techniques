# Optimization-Techniques

# GRADIENT DESCENT:
  
   ðŸ‘‰It is the iterative optimization algorithm used in machine learning to train models.
   
   
   ðŸ‘‰It is also used to train neural networks
   
   
   ðŸ‘‰It helps in finding the local minimum of a function.


![gradient-descent-in-machine-learning1](https://github.com/dharshu2323/Optimization-Techniques/assets/104815447/08e4968e-1e68-429a-a601-30ab34231784)

# MINI-BATCH GRADIENT DESCENT:
   ðŸ‘‰In this algorithm the training dataset is divided into smaller sub-datasets.

   ðŸ‘‰Here we have Dataset Division,Iterative Update,Parameter Update  ,Convergence

   ![download (1)](https://github.com/dharshu2323/Optimization-Techniques/assets/104815447/f8493a36-30f8-49b3-bf89-c0b530c8cc70)


   

 # ADAPTIVE GRADIENT DESCENT:
  ðŸ‘‰In this algorithm adapts learning rates for each parameter individually and incorporates exponential moving averages of gradients 
      and squared gradients.   

![download](https://github.com/dharshu2323/Optimization-Techniques/assets/104815447/d2421010-ddc6-4fa2-a71e-7a3b79d0bea8)

# GENETIC ALGORITHM
   ðŸ‘‰It is a stochastic global optimization algorithm.
   
   
   ðŸ‘‰It is biologically inspired algorithm
   
